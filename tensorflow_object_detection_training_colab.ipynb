{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tony607/object_detection_demo/blob/master/tensorflow_object_detection_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQCnYPVDrsgx"
   },
   "source": [
    "# [How to train an object detection model easy for free](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) | DLology Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhzxsJb3dpWq"
   },
   "source": [
    "## Configs and Hyperparameters\n",
    "\n",
    "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnNXNQCjdniL"
   },
   "outputs": [],
   "source": [
    "# If you forked the repository, you can replace the link.\n",
    "repo_url = 'https://github.com/Tony607/object_detection_demo'\n",
    "\n",
    "# Number of training steps.\n",
    "num_steps = 20000  # 200000\n",
    "\n",
    "# Number of evaluation steps.\n",
    "num_eval_steps = 50\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'rfcn_resnet101': {\n",
    "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
    "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
    "        'batch_size': 8\n",
    "    }\n",
    "}\n",
    "\n",
    "# Pick the model you want to use\n",
    "# Select a model in `MODELS_CONFIG`.\n",
    "selected_model = 'ssd_mobilenet_v2'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4V-XE6kbkc1"
   },
   "source": [
    "## Clone the `object_detection_demo` repository or your fork."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "dxc3DmvLQF3z",
    "outputId": "61c23a22-2e27-40a3-d2b9-965e2ced3738"
   },
   "source": [
    "import os\n",
    "\n",
    "%cd /content\n",
    "\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "\n",
    "!git clone {repo_url}\n",
    "%cd {repo_dir_path}\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bI8__uNS8-ns"
   },
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "ecpHEnka8Kix",
    "outputId": "2d175c62-c801-4f50-813b-cb831387ba08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ghost/Desktop/experiment/models/research\n",
      "a3c_blogpost\t\t\t  marco\n",
      "adversarial_crypto\t\t  maskgan\n",
      "adversarial_logit_pairing\t  morph_net\n",
      "adversarial_text\t\t  namignizer\n",
      "adv_imagenet_models\t\t  neural_gpu\n",
      "astronet\t\t\t  neural_programmer\n",
      "attention_ocr\t\t\t  next_frame_prediction\n",
      "audioset\t\t\t  ngrok\n",
      "autoaugment\t\t\t  ngrok-stable-linux-amd64.zip\n",
      "autoencoder\t\t\t  ngrok-stable-linux-amd64.zip.1\n",
      "brain_coder\t\t\t  nst_blogpost\n",
      "build\t\t\t\t  object_detection\n",
      "cognitive_mapping_and_planning\t  object_detection.egg-info\n",
      "cognitive_planning\t\t  pcl_rl\n",
      "compression\t\t\t  pretrained_model\n",
      "cvt_text\t\t\t  ptn\n",
      "deep_contextual_bandits\t\t  qa_kg\n",
      "deeplab\t\t\t\t  README.md\n",
      "deep_speech\t\t\t  real_nvp\n",
      "delf\t\t\t\t  rebar\n",
      "differential_privacy\t\t  sentiment_analysis\n",
      "dist\t\t\t\t  seq2species\n",
      "domain_adaptation\t\t  setup.py\n",
      "efficient-hrl\t\t\t  skip_thoughts\n",
      "feelvos\t\t\t\t  slim\n",
      "fivo\t\t\t\t  steve\n",
      "global_objectives\t\t  street\n",
      "im2txt\t\t\t\t  struct2depth\n",
      "inception\t\t\t  swivel\n",
      "keypointnet\t\t\t  syntaxnet\n",
      "learned_optimizer\t\t  tcn\n",
      "learning_to_remember_rare_events  tensorrt\n",
      "learning_unsupervised_learning\t  textsum\n",
      "lexnet_nc\t\t\t  training\n",
      "lfads\t\t\t\t  transformer\n",
      "lm_1b\t\t\t\t  vid2depth\n",
      "lm_commonsense\t\t\t  video_prediction\n",
      "lstm_object_detection\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Running tests under Python 3.7.4: /home/ghost/anaconda3/envs/dtoxd/bin/python\n",
      "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
      "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "/home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/data_structures.py:669: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if not isinstance(wrapped_dict, collections.Mapping):\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTest.test_session\n",
      "[  SKIPPED ] ModelBuilderTest.test_session\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 17 tests in 0.234s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/ghost/Desktop/experiment/\n",
    "\n",
    "# !git clone https://github.com/tensorflow/models.git\n",
    "\n",
    "# !apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "# !pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "# !pip install -q pycocotools\n",
    "\n",
    "# %cd /home/ghost/Desktop/experiment/models/research\n",
    "\n",
    "# ! python setup.py build\n",
    "\n",
    "# ! python setup.py install\n",
    "\n",
    "# %cd /home/ghost/Desktop/experiment/models/research/slim\n",
    "\n",
    "# ! pip install -e .\n",
    "\n",
    "%cd /home/ghost/Desktop/experiment/models/research\n",
    "\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "!export PYTHONPATH=$PYTHONPATH:/home/ghost/Desktop/experiment/models/research/:/home/ghost/Desktop/experiment/models/research/slim\n",
    "        \n",
    "! ls\n",
    "\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-k7uGThXlny"
   },
   "source": [
    "## Prepare `tfrecord` files\n",
    "\n",
    "Use the following scripts to generate the `tfrecord` files.\n",
    "```bash\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "ezGDABRXXhPP",
    "outputId": "14197ca2-110c-419e-8a7e-60646285ade1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ghost/Desktop/object_detection_demo\n",
      "Successfully converted xml to csv.\n",
      "Generate `data/annotations/label_map.pbtxt`\n",
      "Successfully converted xml to csv.\n",
      "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W0208 19:04:54.247012 140549989967680 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0208 19:04:54.258589 140549989967680 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Successfully created the TFRecords: /home/ghost/Desktop/object_detection_demo/data/annotations/train.record\n",
      "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W0208 19:04:57.048276 140558865352512 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0208 19:04:57.054518 140558865352512 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Successfully created the TFRecords: /home/ghost/Desktop/object_detection_demo/data/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "repo_dir_path = \"/home/ghost/Desktop/object_detection_demo/\"\n",
    "\n",
    "%cd {repo_dir_path}\n",
    "\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgd-fzAIkZlV"
   },
   "outputs": [],
   "source": [
    "test_record_fname = '/home/ghost/Desktop/object_detection_demo/data/annotations/test.record'\n",
    "train_record_fname = '/home/ghost/Desktop/object_detection_demo/data/annotations/train.record'\n",
    "label_map_pbtxt_fname = '/home/ghost/Desktop/object_detection_demo/data/annotations/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCNYAaC7w6N8"
   },
   "source": [
    "## Download base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "orDCj6ihgUMR",
    "outputId": "c6e66c92-176e-4dbf-9684-0e73b1930bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ghost/Desktop/experiment/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ghost/Desktop/experiment/models/research\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = '/home/ghost/Desktop/experiment/models/research/pretrained_model'\n",
    "\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "pGhvAObeiIix",
    "outputId": "7ffdf9d3-4359-4915-f34b-a70183011fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ghost/Desktop/experiment/models/research/pretrained_model\n",
      "total 135M\n",
      "drwxr-xr-x  3 ghost ghost 4.0K Mar 30  2018 .\n",
      "drwxr-xr-x 72 ghost ghost 4.0K Feb  8 19:06 ..\n",
      "-rw-r--r--  1 ghost ghost   77 Mar 30  2018 checkpoint\n",
      "-rw-r--r--  1 ghost ghost  67M Mar 30  2018 frozen_inference_graph.pb\n",
      "-rw-r--r--  1 ghost ghost  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
      "-rw-r--r--  1 ghost ghost  15K Mar 30  2018 model.ckpt.index\n",
      "-rw-r--r--  1 ghost ghost 3.4M Mar 30  2018 model.ckpt.meta\n",
      "-rw-r--r--  1 ghost ghost 4.2K Mar 30  2018 pipeline.config\n",
      "drwxr-xr-x  3 ghost ghost 4.0K Mar 30  2018 saved_model\n"
     ]
    }
   ],
   "source": [
    "!echo {DEST_DIR}\n",
    "!ls -alh {DEST_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UHnxlfRznPP3",
    "outputId": "88c8904e-2f26-4288-f9bb-a1a4da6d1434"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ghost/Desktop/experiment/models/research/pretrained_model/model.ckpt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "fine_tune_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvwtHlLOeRJD"
   },
   "source": [
    "## Configuring a Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIhw7IdpLuiU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "pipeline_fname = os.path.join('/home/ghost/Desktop/experiment/models/research/object_detection/samples/configs/', pipeline_file)\n",
    "\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG1nCNpUXcRU"
   },
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjtCbLF2i0wI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ghost/Desktop/experiment/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open(pipeline_fname, 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2490
    },
    "colab_type": "code",
    "id": "GH0MEEanocn6",
    "outputId": "a8fb1e43-21fb-43f5-e071-8575924a19a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\r\n",
      "# Users should configure the fine_tune_checkpoint field in the train config as\r\n",
      "# well as the label_map_path and input_path fields in the train_input_reader and\r\n",
      "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n",
      "# should be configured.\r\n",
      "\r\n",
      "model {\r\n",
      "  ssd {\r\n",
      "    num_classes: 4\r\n",
      "    box_coder {\r\n",
      "      faster_rcnn_box_coder {\r\n",
      "        y_scale: 10.0\r\n",
      "        x_scale: 10.0\r\n",
      "        height_scale: 5.0\r\n",
      "        width_scale: 5.0\r\n",
      "      }\r\n",
      "    }\r\n",
      "    matcher {\r\n",
      "      argmax_matcher {\r\n",
      "        matched_threshold: 0.5\r\n",
      "        unmatched_threshold: 0.5\r\n",
      "        ignore_thresholds: false\r\n",
      "        negatives_lower_than_unmatched: true\r\n",
      "        force_match_for_each_row: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    similarity_calculator {\r\n",
      "      iou_similarity {\r\n",
      "      }\r\n",
      "    }\r\n",
      "    anchor_generator {\r\n",
      "      ssd_anchor_generator {\r\n",
      "        num_layers: 6\r\n",
      "        min_scale: 0.2\r\n",
      "        max_scale: 0.95\r\n",
      "        aspect_ratios: 1.0\r\n",
      "        aspect_ratios: 2.0\r\n",
      "        aspect_ratios: 0.5\r\n",
      "        aspect_ratios: 3.0\r\n",
      "        aspect_ratios: 0.3333\r\n",
      "      }\r\n",
      "    }\r\n",
      "    image_resizer {\r\n",
      "      fixed_shape_resizer {\r\n",
      "        height: 300\r\n",
      "        width: 300\r\n",
      "      }\r\n",
      "    }\r\n",
      "    box_predictor {\r\n",
      "      convolutional_box_predictor {\r\n",
      "        min_depth: 0\r\n",
      "        max_depth: 0\r\n",
      "        num_layers_before_predictor: 0\r\n",
      "        use_dropout: false\r\n",
      "        dropout_keep_probability: 0.8\r\n",
      "        kernel_size: 1\r\n",
      "        box_code_size: 4\r\n",
      "        apply_sigmoid_to_scores: false\r\n",
      "        conv_hyperparams {\r\n",
      "          activation: RELU_6,\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 0.00004\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            truncated_normal_initializer {\r\n",
      "              stddev: 0.03\r\n",
      "              mean: 0.0\r\n",
      "            }\r\n",
      "          }\r\n",
      "          batch_norm {\r\n",
      "            train: true,\r\n",
      "            scale: true,\r\n",
      "            center: true,\r\n",
      "            decay: 0.9997,\r\n",
      "            epsilon: 0.001,\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    feature_extractor {\r\n",
      "      type: 'ssd_mobilenet_v2'\r\n",
      "      min_depth: 16\r\n",
      "      depth_multiplier: 1.0\r\n",
      "      conv_hyperparams {\r\n",
      "        activation: RELU_6,\r\n",
      "        regularizer {\r\n",
      "          l2_regularizer {\r\n",
      "            weight: 0.00004\r\n",
      "          }\r\n",
      "        }\r\n",
      "        initializer {\r\n",
      "          truncated_normal_initializer {\r\n",
      "            stddev: 0.03\r\n",
      "            mean: 0.0\r\n",
      "          }\r\n",
      "        }\r\n",
      "        batch_norm {\r\n",
      "          train: true,\r\n",
      "          scale: true,\r\n",
      "          center: true,\r\n",
      "          decay: 0.9997,\r\n",
      "          epsilon: 0.001,\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    loss {\r\n",
      "      classification_loss {\r\n",
      "        weighted_sigmoid {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      localization_loss {\r\n",
      "        weighted_smooth_l1 {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      hard_example_miner {\r\n",
      "        num_hard_examples: 3000\r\n",
      "        iou_threshold: 0.99\r\n",
      "        loss_type: CLASSIFICATION\r\n",
      "        max_negatives_per_positive: 3\r\n",
      "        min_negatives_per_image: 3\r\n",
      "      }\r\n",
      "      classification_weight: 1.0\r\n",
      "      localization_weight: 1.0\r\n",
      "    }\r\n",
      "    normalize_loss_by_num_matches: true\r\n",
      "    post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 1e-8\r\n",
      "        iou_threshold: 0.6\r\n",
      "        max_detections_per_class: 100\r\n",
      "        max_total_detections: 100\r\n",
      "      }\r\n",
      "      score_converter: SIGMOID\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "train_config: {\r\n",
      "  batch_size: 12\r\n",
      "  optimizer {\r\n",
      "    rms_prop_optimizer: {\r\n",
      "      learning_rate: {\r\n",
      "        exponential_decay_learning_rate {\r\n",
      "          initial_learning_rate: 0.004\r\n",
      "          decay_steps: 800720\r\n",
      "          decay_factor: 0.95\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.9\r\n",
      "      decay: 0.9\r\n",
      "      epsilon: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  fine_tune_checkpoint: \"/home/ghost/Desktop/experiment/models/research/pretrained_model/model.ckpt\"\r\n",
      "  fine_tune_checkpoint_type:  \"detection\"\r\n",
      "  # Note: The below line limits the training process to 200K steps, which we\r\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\r\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\r\n",
      "  # never decay). Remove the below line to train indefinitely.\r\n",
      "  num_steps: 20000\r\n",
      "  data_augmentation_options {\r\n",
      "    random_horizontal_flip {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  data_augmentation_options {\r\n",
      "    ssd_random_crop {\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "train_input_reader: {\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/home/ghost/Desktop/object_detection_demo/data/annotations/train.record\"\r\n",
      "  }\r\n",
      "  label_map_path: \"/home/ghost/Desktop/object_detection_demo/data/annotations/label_map.pbtxt\"\r\n",
      "}\r\n",
      "\r\n",
      "eval_config: {\r\n",
      "  num_examples: 8000\r\n",
      "  # Note: The below line limits the evaluation process to 10 evaluations.\r\n",
      "  # Remove the below line to evaluate indefinitely.\r\n",
      "  max_evals: 10\r\n",
      "}\r\n",
      "\r\n",
      "eval_input_reader: {\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/home/ghost/Desktop/object_detection_demo/data/annotations/test.record\"\r\n",
      "  }\r\n",
      "  label_map_path: \"/home/ghost/Desktop/object_detection_demo/data/annotations/label_map.pbtxt\"\r\n",
      "  shuffle: false\r\n",
      "  num_readers: 1\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat {pipeline_fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f11w0uO3jFCB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ghost/Desktop/experiment/models/research\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "model_dir = 'training/'\n",
    "# Optionally remove content in output model directory to fresh start.\n",
    "!rm -rf {model_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23TECXvNezIF"
   },
   "source": [
    "## Run Tensorboard(Optional)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "0H2PZs-mSCmO",
    "outputId": "468bbcb1-82ce-4e58-dff2-179ff9907d29"
   },
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8o6r1o5SC5M"
   },
   "source": [
    "LOG_DIR = model_dir\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ge1OX7gcSC7S"
   },
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5GSGxZNh8rp"
   },
   "source": [
    "### Get Tensorboard link"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rjhPT9iPSJ6T",
    "outputId": "5259af87-6ae2-4461-db20-850fce5e8a9a"
   },
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDddx2rPfex9"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nC7_syR1SJ9F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ghost/Desktop/experiment/models/research\n",
      "/home/ghost/Desktop/experiment\n",
      "fatal: destination path 'cocoapi' already exists and is not an empty directory.\n",
      "/home/ghost/Desktop/experiment/cocoapi/PythonAPI\n",
      "python setup.py build_ext --inplace\n",
      "running build_ext\n",
      "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
      "rm -rf build\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/pycocotools\n",
      "copying pycocotools/mask.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
      "copying pycocotools/coco.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
      "copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
      "copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.7/pycocotools\n",
      "running build_ext\n",
      "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.7\n",
      "creating build/temp.linux-x86_64-3.7/pycocotools\n",
      "gcc -pthread -B /home/ghost/anaconda3/envs/dtoxd/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/numpy/core/include -I../common -I/home/ghost/anaconda3/envs/dtoxd/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
      "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "gcc -pthread -B /home/ghost/anaconda3/envs/dtoxd/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/numpy/core/include -I../common -I/home/ghost/anaconda3/envs/dtoxd/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "gcc -pthread -shared -B /home/ghost/anaconda3/envs/dtoxd/compiler_compat -L/home/ghost/anaconda3/envs/dtoxd/lib -Wl,-rpath=/home/ghost/anaconda3/envs/dtoxd/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing pycocotools.egg-info/PKG-INFO\n",
      "writing dependency_links to pycocotools.egg-info/dependency_links.txt\n",
      "writing requirements to pycocotools.egg-info/requires.txt\n",
      "writing top-level names to pycocotools.egg-info/top_level.txt\n",
      "reading manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "running build_ext\n",
      "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-37.pyc\n",
      "creating stub loader for pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "pycocotools.__pycache__._mask.cpython-37: module references __file__\n",
      "creating 'dist/pycocotools-2.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing pycocotools-2.0-py3.7-linux-x86_64.egg\n",
      "removing '/home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg' (and everything under it)\n",
      "creating /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg\n",
      "Extracting pycocotools-2.0-py3.7-linux-x86_64.egg to /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "pycocotools 2.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg\n",
      "Processing dependencies for pycocotools==2.0\n",
      "Searching for matplotlib==3.1.1\n",
      "Best match: matplotlib 3.1.1\n",
      "Adding matplotlib 3.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Searching for Cython==0.29.14\n",
      "Best match: Cython 0.29.14\n",
      "Adding Cython 0.29.14 to easy-install.pth file\n",
      "Installing cygdb script to /home/ghost/anaconda3/envs/dtoxd/bin\n",
      "Installing cython script to /home/ghost/anaconda3/envs/dtoxd/bin\n",
      "Installing cythonize script to /home/ghost/anaconda3/envs/dtoxd/bin\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Searching for setuptools==42.0.2.post20191203\n",
      "Best match: setuptools 42.0.2.post20191203\n",
      "Adding setuptools 42.0.2.post20191203 to easy-install.pth file\n",
      "Installing easy_install script to /home/ghost/anaconda3/envs/dtoxd/bin\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Searching for python-dateutil==2.8.0\n",
      "Best match: python-dateutil 2.8.0\n",
      "Adding python-dateutil 2.8.0 to easy-install.pth file\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Searching for numpy==1.16.5\n",
      "Best match: numpy 1.16.5\n",
      "Adding numpy 1.16.5 to easy-install.pth file\n",
      "Installing f2py script to /home/ghost/anaconda3/envs/dtoxd/bin\n",
      "Installing f2py3 script to /home/ghost/anaconda3/envs/dtoxd/bin\n",
      "Installing f2py3.7 script to /home/ghost/anaconda3/envs/dtoxd/bin\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Searching for pyparsing==2.4.2\n",
      "Best match: pyparsing 2.4.2\n",
      "Adding pyparsing 2.4.2 to easy-install.pth file\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Searching for kiwisolver==1.1.0\n",
      "Best match: kiwisolver 1.1.0\n",
      "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Searching for six==1.13.0\n",
      "Best match: six 1.13.0\n",
      "Adding six 1.13.0 to easy-install.pth file\n",
      "\n",
      "Using /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages\n",
      "Finished processing dependencies for pycocotools==2.0\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "%cd /home/ghost/Desktop/experiment/\n",
    "\n",
    "! git clone https://github.com/cocodataset/cocoapi.git\n",
    "\n",
    "%cd cocoapi/PythonAPI\n",
    "\n",
    "!make\n",
    "\n",
    "!python setup.py build\n",
    "\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6655
    },
    "colab_type": "code",
    "id": "CjDHjhKQofT5",
    "outputId": "572ae2e8-9c77-4b42-cd9a-3f987ff93d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/Desktop/experiment/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0208 19:08:18.794018 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "W0208 19:08:18.797579 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0208 19:08:18.797749 140033311766336 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0208 19:08:18.797884 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 20000\n",
      "I0208 19:08:18.797984 140033311766336 config_util.py:488] Maybe overwriting train_steps: 20000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0208 19:08:18.798078 140033311766336 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0208 19:08:18.798159 140033311766336 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0208 19:08:18.798258 140033311766336 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
      "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
      "I0208 19:08:18.798370 140033311766336 config_util.py:488] Maybe overwriting load_pretrained: True\n",
      "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
      "I0208 19:08:18.798431 140033311766336 config_util.py:498] Ignoring config override key: load_pretrained\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0208 19:08:18.798602 140033311766336 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "I0208 19:08:18.798713 140033311766336 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5b8ec2fa50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0208 19:08:18.799113 140033311766336 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5b8ec2fa50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5b8ec2cc20>) includes params argument, but params are not passed to Estimator.\n",
      "W0208 19:08:18.799312 140033311766336 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5b8ec2cc20>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0208 19:08:18.799710 140033311766336 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0208 19:08:18.799897 140033311766336 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0208 19:08:18.800107 140033311766336 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0208 19:08:18.808289 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0208 19:08:18.817455 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W0208 19:08:18.817742 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0208 19:08:18.830682 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0208 19:08:18.831362 140033311766336 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W0208 19:08:18.838284 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0208 19:08:18.838500 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0208 19:08:18.865488 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
      "\n",
      "W0208 19:08:20.311439 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "W0208 19:08:28.228826 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0208 19:08:28.319365 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0208 19:08:30.599872 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0208 19:08:33.909451 140033311766336 api.py:332] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0208 19:08:37.252382 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0208 19:08:37.253579 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0208 19:08:37.765804 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
      "\n",
      "W0208 19:08:39.466968 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "W0208 19:08:39.974833 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 19:08:39.987088 140033311766336 estimator.py:1148] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0208 19:08:40.168653 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0208 19:08:40.168960 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0208 19:08:40.171188 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W0208 19:08:43.138568 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:08:43.148971 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:08:43.185820 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:08:43.225338 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:08:43.262857 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:08:43.301856 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:08:43.340442 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0208 19:08:43.382680 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "W0208 19:08:43.383785 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "W0208 19:08:43.388499 140033311766336 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
      "W0208 19:08:43.388692 140033311766336 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
      "W0208 19:08:43.388800 140033311766336 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
      "W0208 19:08:43.388899 140033311766336 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W0208 19:08:43.389167 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0208 19:08:44.322104 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0208 19:08:46.226948 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "W0208 19:08:46.232686 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0208 19:08:46.234054 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0208 19:08:46.545308 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0208 19:08:46.547931 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "W0208 19:08:46.548311 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "W0208 19:08:46.561367 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0208 19:08:46.561733 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0208 19:08:48.392955 140033311766336 deprecation.py:506] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0208 19:08:54.245405 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0208 19:08:55.099152 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
      "\n",
      "W0208 19:08:55.099400 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 19:08:55.099790 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0208 19:08:55.101108 140033311766336 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 19:08:58.694616 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "2020-02-08 19:08:58.694995: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-02-08 19:08:58.721465: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz\n",
      "2020-02-08 19:08:58.721971: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e1cd5f1030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-02-08 19:08:58.722027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-02-08 19:08:58.724763: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-02-08 19:08:58.724798: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-02-08 19:08:58.724827: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ghost): /proc/driver/nvidia/version does not exist\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-0\n",
      "I0208 19:08:58.727180 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-0\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "W0208 19:09:02.245903 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 19:09:04.990674 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 19:09:05.426146 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
      "I0208 19:09:17.283720 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
      "INFO:tensorflow:loss = 21.71253, step = 1\n",
      "I0208 19:09:33.268504 140033311766336 basic_session_run_hooks.py:262] loss = 21.71253, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.296784\n",
      "I0208 19:15:10.212962 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.296784\n",
      "INFO:tensorflow:loss = 7.6305714, step = 101 (336.945 sec)\n",
      "I0208 19:15:10.213797 140033311766336 basic_session_run_hooks.py:260] loss = 7.6305714, step = 101 (336.945 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 175 into training/model.ckpt.\n",
      "I0208 19:19:21.533400 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 175 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 19:19:23.945573 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:19:26.590701 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:19:26.627496 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:19:26.665078 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:19:26.701157 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:19:26.734777 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:19:26.770682 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0208 19:19:27.599030 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0208 19:19:27.810405 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "W0208 19:19:27.964898 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\n",
      "W0208 19:19:28.051206 140033311766336 module_wrapper.py:139] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 19:19:28.419039 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T19:19:28Z\n",
      "I0208 19:19:28.440065 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T19:19:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 19:19:28.877258 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-175\n",
      "I0208 19:19:28.878615 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-175\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 19:19:30.694193 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 19:19:30.855151 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 19:19:37.420595 140030379005696 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 19:19:37.421254 140030379005696 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 19:19:37.423871 140030379005696 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.089\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-19:19:38\n",
      "I0208 19:19:38.061747 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-19:19:38\n",
      "INFO:tensorflow:Saving dict for global step 175: DetectionBoxes_Precision/mAP = 0.11978699, DetectionBoxes_Precision/mAP (large) = 0.12976415, DetectionBoxes_Precision/mAP (medium) = 0.04082135, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.29305923, DetectionBoxes_Precision/mAP@.75IOU = 0.07710981, DetectionBoxes_Recall/AR@1 = 0.10217865, DetectionBoxes_Recall/AR@10 = 0.2784314, DetectionBoxes_Recall/AR@100 = 0.30501089, DetectionBoxes_Recall/AR@100 (large) = 0.33444443, DetectionBoxes_Recall/AR@100 (medium) = 0.08888889, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.2661343, Loss/localization_loss = 2.450978, Loss/regularization_loss = 0.24818216, Loss/total_loss = 9.965295, global_step = 175, learning_rate = 0.004, loss = 9.965295\n",
      "I0208 19:19:38.061975 140033311766336 estimator.py:2049] Saving dict for global step 175: DetectionBoxes_Precision/mAP = 0.11978699, DetectionBoxes_Precision/mAP (large) = 0.12976415, DetectionBoxes_Precision/mAP (medium) = 0.04082135, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.29305923, DetectionBoxes_Precision/mAP@.75IOU = 0.07710981, DetectionBoxes_Recall/AR@1 = 0.10217865, DetectionBoxes_Recall/AR@10 = 0.2784314, DetectionBoxes_Recall/AR@100 = 0.30501089, DetectionBoxes_Recall/AR@100 (large) = 0.33444443, DetectionBoxes_Recall/AR@100 (medium) = 0.08888889, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.2661343, Loss/localization_loss = 2.450978, Loss/regularization_loss = 0.24818216, Loss/total_loss = 9.965295, global_step = 175, learning_rate = 0.004, loss = 9.965295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 175: training/model.ckpt-175\n",
      "I0208 19:19:38.815082 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 175: training/model.ckpt-175\n",
      "INFO:tensorflow:global_step/sec: 0.281646\n",
      "I0208 19:21:05.268642 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.281646\n",
      "INFO:tensorflow:loss = 6.715046, step = 201 (355.056 sec)\n",
      "I0208 19:21:05.269372 140033311766336 basic_session_run_hooks.py:260] loss = 6.715046, step = 201 (355.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301168\n",
      "I0208 19:26:37.308708 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.301168\n",
      "INFO:tensorflow:loss = 5.965867, step = 301 (332.040 sec)\n",
      "I0208 19:26:37.309445 140033311766336 basic_session_run_hooks.py:260] loss = 5.965867, step = 301 (332.040 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 351 into training/model.ckpt.\n",
      "I0208 19:29:22.202684 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 351 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 19:29:24.329576 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:29:27.039735 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:29:27.079051 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:29:27.116525 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:29:27.156724 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:29:27.195918 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:29:27.235689 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 19:29:28.780347 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T19:29:28Z\n",
      "I0208 19:29:28.797591 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T19:29:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 19:29:29.230115 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-351\n",
      "I0208 19:29:29.231365 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-351\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 19:29:31.286313 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 19:29:31.463147 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 19:29:37.667328 140030379005696 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 19:29:37.668071 140030379005696 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 19:29:37.671390 140030379005696 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.508\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.061\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-19:29:38\n",
      "I0208 19:29:38.205254 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-19:29:38\n",
      "INFO:tensorflow:Saving dict for global step 351: DetectionBoxes_Precision/mAP = 0.17527048, DetectionBoxes_Precision/mAP (large) = 0.19055186, DetectionBoxes_Precision/mAP (medium) = 0.13439505, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.50845987, DetectionBoxes_Precision/mAP@.75IOU = 0.060754884, DetectionBoxes_Recall/AR@1 = 0.16209151, DetectionBoxes_Recall/AR@10 = 0.37995642, DetectionBoxes_Recall/AR@100 = 0.38366014, DetectionBoxes_Recall/AR@100 (large) = 0.385, DetectionBoxes_Recall/AR@100 (medium) = 0.3888889, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.6039863, Loss/localization_loss = 2.2839344, Loss/regularization_loss = 0.24870394, Loss/total_loss = 9.136626, global_step = 351, learning_rate = 0.004, loss = 9.136626\n",
      "I0208 19:29:38.205478 140033311766336 estimator.py:2049] Saving dict for global step 351: DetectionBoxes_Precision/mAP = 0.17527048, DetectionBoxes_Precision/mAP (large) = 0.19055186, DetectionBoxes_Precision/mAP (medium) = 0.13439505, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.50845987, DetectionBoxes_Precision/mAP@.75IOU = 0.060754884, DetectionBoxes_Recall/AR@1 = 0.16209151, DetectionBoxes_Recall/AR@10 = 0.37995642, DetectionBoxes_Recall/AR@100 = 0.38366014, DetectionBoxes_Recall/AR@100 (large) = 0.385, DetectionBoxes_Recall/AR@100 (medium) = 0.3888889, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.6039863, Loss/localization_loss = 2.2839344, Loss/regularization_loss = 0.24870394, Loss/total_loss = 9.136626, global_step = 351, learning_rate = 0.004, loss = 9.136626\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 351: training/model.ckpt-351\n",
      "I0208 19:29:38.207709 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 351: training/model.ckpt-351\n",
      "INFO:tensorflow:global_step/sec: 0.289811\n",
      "I0208 19:32:22.360800 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.289811\n",
      "INFO:tensorflow:loss = 6.114238, step = 401 (345.052 sec)\n",
      "I0208 19:32:22.361784 140033311766336 basic_session_run_hooks.py:260] loss = 6.114238, step = 401 (345.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302622\n",
      "I0208 19:37:52.805784 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.302622\n",
      "INFO:tensorflow:loss = 5.666647, step = 501 (330.445 sec)\n",
      "I0208 19:37:52.806793 140033311766336 basic_session_run_hooks.py:260] loss = 5.666647, step = 501 (330.445 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 529 into training/model.ckpt.\n",
      "I0208 19:39:24.961019 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 529 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 19:39:27.093772 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:39:29.496200 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:39:29.536354 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:39:29.573958 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:39:29.613163 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:39:29.653845 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:39:29.694444 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 19:39:31.255130 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T19:39:31Z\n",
      "I0208 19:39:31.273137 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T19:39:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 19:39:32.019807 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-529\n",
      "I0208 19:39:32.020967 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-529\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 19:39:34.160678 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 19:39:34.342093 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 19:39:40.552480 140030026708736 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 19:39:40.553283 140030026708736 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 19:39:40.557528 140030026708736 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.596\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-19:39:41\n",
      "I0208 19:39:41.082850 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-19:39:41\n",
      "INFO:tensorflow:Saving dict for global step 529: DetectionBoxes_Precision/mAP = 0.24689996, DetectionBoxes_Precision/mAP (large) = 0.25524125, DetectionBoxes_Precision/mAP (medium) = 0.30693462, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5962719, DetectionBoxes_Precision/mAP@.75IOU = 0.15958652, DetectionBoxes_Recall/AR@1 = 0.24379085, DetectionBoxes_Recall/AR@10 = 0.40152505, DetectionBoxes_Recall/AR@100 = 0.43137255, DetectionBoxes_Recall/AR@100 (large) = 0.4261111, DetectionBoxes_Recall/AR@100 (medium) = 0.45555556, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.231773, Loss/localization_loss = 1.8844752, Loss/regularization_loss = 0.24926983, Loss/total_loss = 8.365518, global_step = 529, learning_rate = 0.004, loss = 8.365518\n",
      "I0208 19:39:41.083090 140033311766336 estimator.py:2049] Saving dict for global step 529: DetectionBoxes_Precision/mAP = 0.24689996, DetectionBoxes_Precision/mAP (large) = 0.25524125, DetectionBoxes_Precision/mAP (medium) = 0.30693462, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5962719, DetectionBoxes_Precision/mAP@.75IOU = 0.15958652, DetectionBoxes_Recall/AR@1 = 0.24379085, DetectionBoxes_Recall/AR@10 = 0.40152505, DetectionBoxes_Recall/AR@100 = 0.43137255, DetectionBoxes_Recall/AR@100 (large) = 0.4261111, DetectionBoxes_Recall/AR@100 (medium) = 0.45555556, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.231773, Loss/localization_loss = 1.8844752, Loss/regularization_loss = 0.24926983, Loss/total_loss = 8.365518, global_step = 529, learning_rate = 0.004, loss = 8.365518\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 529: training/model.ckpt-529\n",
      "I0208 19:39:41.086099 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 529: training/model.ckpt-529\n",
      "INFO:tensorflow:global_step/sec: 0.288721\n",
      "I0208 19:43:39.160479 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.288721\n",
      "INFO:tensorflow:loss = 4.6816516, step = 601 (346.354 sec)\n",
      "I0208 19:43:39.161258 140033311766336 basic_session_run_hooks.py:260] loss = 4.6816516, step = 601 (346.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.297635\n",
      "I0208 19:49:15.142241 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.297635\n",
      "INFO:tensorflow:loss = 5.128891, step = 701 (335.982 sec)\n",
      "I0208 19:49:15.142941 140033311766336 basic_session_run_hooks.py:260] loss = 5.128891, step = 701 (335.982 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 704 into training/model.ckpt.\n",
      "I0208 19:49:25.074822 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 704 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 19:49:27.257021 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:49:29.634853 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:49:29.668359 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:49:29.710214 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:49:29.747471 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:49:29.790236 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:49:29.828985 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 19:49:31.383385 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T19:49:31Z\n",
      "I0208 19:49:31.400499 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T19:49:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 19:49:31.829843 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-704\n",
      "I0208 19:49:31.831362 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-704\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 19:49:33.857894 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 19:49:34.029701 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 19:49:40.340193 140030026708736 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 19:49:40.341164 140030026708736 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 19:49:40.345357 140030026708736 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.430\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-19:49:40\n",
      "I0208 19:49:40.971803 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-19:49:40\n",
      "INFO:tensorflow:Saving dict for global step 704: DetectionBoxes_Precision/mAP = 0.24917339, DetectionBoxes_Precision/mAP (large) = 0.25446698, DetectionBoxes_Precision/mAP (medium) = 0.47190005, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6517267, DetectionBoxes_Precision/mAP@.75IOU = 0.14114805, DetectionBoxes_Recall/AR@1 = 0.29956427, DetectionBoxes_Recall/AR@10 = 0.4298475, DetectionBoxes_Recall/AR@100 = 0.4335512, DetectionBoxes_Recall/AR@100 (large) = 0.42944443, DetectionBoxes_Recall/AR@100 (medium) = 0.53333336, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.1443977, Loss/localization_loss = 1.8181281, Loss/regularization_loss = 0.2498783, Loss/total_loss = 8.212404, global_step = 704, learning_rate = 0.004, loss = 8.212404\n",
      "I0208 19:49:40.972037 140033311766336 estimator.py:2049] Saving dict for global step 704: DetectionBoxes_Precision/mAP = 0.24917339, DetectionBoxes_Precision/mAP (large) = 0.25446698, DetectionBoxes_Precision/mAP (medium) = 0.47190005, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6517267, DetectionBoxes_Precision/mAP@.75IOU = 0.14114805, DetectionBoxes_Recall/AR@1 = 0.29956427, DetectionBoxes_Recall/AR@10 = 0.4298475, DetectionBoxes_Recall/AR@100 = 0.4335512, DetectionBoxes_Recall/AR@100 (large) = 0.42944443, DetectionBoxes_Recall/AR@100 (medium) = 0.53333336, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.1443977, Loss/localization_loss = 1.8181281, Loss/regularization_loss = 0.2498783, Loss/total_loss = 8.212404, global_step = 704, learning_rate = 0.004, loss = 8.212404\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 704: training/model.ckpt-704\n",
      "I0208 19:49:40.974658 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 704: training/model.ckpt-704\n",
      "INFO:tensorflow:global_step/sec: 0.28863\n",
      "I0208 19:55:01.606771 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.28863\n",
      "INFO:tensorflow:loss = 4.732962, step = 801 (346.465 sec)\n",
      "I0208 19:55:01.607521 140033311766336 basic_session_run_hooks.py:260] loss = 4.732962, step = 801 (346.465 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 881 into training/model.ckpt.\n",
      "I0208 19:59:25.704311 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 881 into training/model.ckpt.\n",
      "WARNING:tensorflow:From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "W0208 19:59:25.782343 140033311766336 deprecation.py:323] From /home/ghost/anaconda3/envs/dtoxd/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 19:59:27.834036 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:59:30.235921 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:59:30.278705 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:59:30.316135 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:59:30.354725 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:59:30.394081 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 19:59:30.434044 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 19:59:32.407917 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T19:59:32Z\n",
      "I0208 19:59:32.425310 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T19:59:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 19:59:32.853380 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-881\n",
      "I0208 19:59:32.854626 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-881\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 19:59:34.992284 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 19:59:35.175085 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 19:59:41.468312 140030387398400 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 19:59:41.469620 140030387398400 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 19:59:41.473101 140030387398400 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.527\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-19:59:42\n",
      "I0208 19:59:42.076581 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-19:59:42\n",
      "INFO:tensorflow:Saving dict for global step 881: DetectionBoxes_Precision/mAP = 0.23883404, DetectionBoxes_Precision/mAP (large) = 0.26030365, DetectionBoxes_Precision/mAP (medium) = 0.11079208, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5268649, DetectionBoxes_Precision/mAP@.75IOU = 0.20052476, DetectionBoxes_Recall/AR@1 = 0.21045752, DetectionBoxes_Recall/AR@10 = 0.38627452, DetectionBoxes_Recall/AR@100 = 0.3899782, DetectionBoxes_Recall/AR@100 (large) = 0.41472223, DetectionBoxes_Recall/AR@100 (medium) = 0.33333334, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.227772, Loss/localization_loss = 1.790635, Loss/regularization_loss = 0.25050595, Loss/total_loss = 9.268914, global_step = 881, learning_rate = 0.004, loss = 9.268914\n",
      "I0208 19:59:42.076815 140033311766336 estimator.py:2049] Saving dict for global step 881: DetectionBoxes_Precision/mAP = 0.23883404, DetectionBoxes_Precision/mAP (large) = 0.26030365, DetectionBoxes_Precision/mAP (medium) = 0.11079208, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5268649, DetectionBoxes_Precision/mAP@.75IOU = 0.20052476, DetectionBoxes_Recall/AR@1 = 0.21045752, DetectionBoxes_Recall/AR@10 = 0.38627452, DetectionBoxes_Recall/AR@100 = 0.3899782, DetectionBoxes_Recall/AR@100 (large) = 0.41472223, DetectionBoxes_Recall/AR@100 (medium) = 0.33333334, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.227772, Loss/localization_loss = 1.790635, Loss/regularization_loss = 0.25050595, Loss/total_loss = 9.268914, global_step = 881, learning_rate = 0.004, loss = 9.268914\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 881: training/model.ckpt-881\n",
      "I0208 19:59:42.079334 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 881: training/model.ckpt-881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.288642\n",
      "I0208 20:00:48.056188 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.288642\n",
      "INFO:tensorflow:loss = 4.2014136, step = 901 (346.449 sec)\n",
      "I0208 20:00:48.056898 140033311766336 basic_session_run_hooks.py:260] loss = 4.2014136, step = 901 (346.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303299\n",
      "I0208 20:06:17.764319 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.303299\n",
      "INFO:tensorflow:loss = 4.68996, step = 1001 (329.708 sec)\n",
      "I0208 20:06:17.765171 140033311766336 basic_session_run_hooks.py:260] loss = 4.68996, step = 1001 (329.708 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1059 into training/model.ckpt.\n",
      "I0208 20:09:28.565161 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 1059 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 20:09:30.744916 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:09:33.136945 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:09:33.175468 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:09:33.209851 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:09:33.251186 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:09:33.290633 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:09:33.328227 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 20:09:34.891951 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T20:09:34Z\n",
      "I0208 20:09:34.917136 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T20:09:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 20:09:35.350273 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-1059\n",
      "I0208 20:09:35.351701 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-1059\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 20:09:37.411834 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 20:09:37.582505 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 20:09:43.995518 140030026708736 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 20:09:43.995975 140030026708736 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 20:09:43.998331 140030026708736 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-20:09:44\n",
      "I0208 20:09:44.540668 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-20:09:44\n",
      "INFO:tensorflow:Saving dict for global step 1059: DetectionBoxes_Precision/mAP = 0.31098887, DetectionBoxes_Precision/mAP (large) = 0.34519655, DetectionBoxes_Precision/mAP (medium) = 0.26561728, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.68531895, DetectionBoxes_Precision/mAP@.75IOU = 0.2566619, DetectionBoxes_Recall/AR@1 = 0.3156863, DetectionBoxes_Recall/AR@10 = 0.51525056, DetectionBoxes_Recall/AR@100 = 0.5189543, DetectionBoxes_Recall/AR@100 (large) = 0.5541667, DetectionBoxes_Recall/AR@100 (medium) = 0.3888889, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.0390515, Loss/localization_loss = 1.716481, Loss/regularization_loss = 0.2511573, Loss/total_loss = 8.00669, global_step = 1059, learning_rate = 0.004, loss = 8.00669\n",
      "I0208 20:09:44.540889 140033311766336 estimator.py:2049] Saving dict for global step 1059: DetectionBoxes_Precision/mAP = 0.31098887, DetectionBoxes_Precision/mAP (large) = 0.34519655, DetectionBoxes_Precision/mAP (medium) = 0.26561728, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.68531895, DetectionBoxes_Precision/mAP@.75IOU = 0.2566619, DetectionBoxes_Recall/AR@1 = 0.3156863, DetectionBoxes_Recall/AR@10 = 0.51525056, DetectionBoxes_Recall/AR@100 = 0.5189543, DetectionBoxes_Recall/AR@100 (large) = 0.5541667, DetectionBoxes_Recall/AR@100 (medium) = 0.3888889, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.0390515, Loss/localization_loss = 1.716481, Loss/regularization_loss = 0.2511573, Loss/total_loss = 8.00669, global_step = 1059, learning_rate = 0.004, loss = 8.00669\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1059: training/model.ckpt-1059\n",
      "I0208 20:09:44.543234 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1059: training/model.ckpt-1059\n",
      "INFO:tensorflow:global_step/sec: 0.289907\n",
      "I0208 20:12:02.702548 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.289907\n",
      "INFO:tensorflow:loss = 4.018693, step = 1101 (344.938 sec)\n",
      "I0208 20:12:02.703253 140033311766336 basic_session_run_hooks.py:260] loss = 4.018693, step = 1101 (344.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303687\n",
      "I0208 20:17:31.988906 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.303687\n",
      "INFO:tensorflow:loss = 3.5234227, step = 1201 (329.286 sec)\n",
      "I0208 20:17:31.989732 140033311766336 basic_session_run_hooks.py:260] loss = 3.5234227, step = 1201 (329.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1237 into training/model.ckpt.\n",
      "I0208 20:19:30.378031 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 1237 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 20:19:32.491582 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:19:35.290946 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:19:35.330572 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:19:35.367147 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:19:35.405564 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:19:35.444127 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:19:35.484005 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 20:19:37.038607 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T20:19:37Z\n",
      "I0208 20:19:37.055806 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T20:19:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 20:19:37.486187 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-1237\n",
      "I0208 20:19:37.487326 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-1237\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 20:19:39.244101 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 20:19:39.401094 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 20:19:45.976948 140030379005696 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 20:19:45.978087 140030379005696 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 20:19:45.981927 140030379005696 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.506\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.359\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-20:19:46\n",
      "I0208 20:19:46.544938 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-20:19:46\n",
      "INFO:tensorflow:Saving dict for global step 1237: DetectionBoxes_Precision/mAP = 0.19557169, DetectionBoxes_Precision/mAP (large) = 0.20714237, DetectionBoxes_Precision/mAP (medium) = 0.1552216, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5063827, DetectionBoxes_Precision/mAP@.75IOU = 0.11386139, DetectionBoxes_Recall/AR@1 = 0.18453158, DetectionBoxes_Recall/AR@10 = 0.3261438, DetectionBoxes_Recall/AR@100 = 0.32984748, DetectionBoxes_Recall/AR@100 (large) = 0.3586111, DetectionBoxes_Recall/AR@100 (medium) = 0.21666667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.209749, Loss/localization_loss = 2.0638218, Loss/regularization_loss = 0.25180376, Loss/total_loss = 9.525373, global_step = 1237, learning_rate = 0.004, loss = 9.525373\n",
      "I0208 20:19:46.545200 140033311766336 estimator.py:2049] Saving dict for global step 1237: DetectionBoxes_Precision/mAP = 0.19557169, DetectionBoxes_Precision/mAP (large) = 0.20714237, DetectionBoxes_Precision/mAP (medium) = 0.1552216, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5063827, DetectionBoxes_Precision/mAP@.75IOU = 0.11386139, DetectionBoxes_Recall/AR@1 = 0.18453158, DetectionBoxes_Recall/AR@10 = 0.3261438, DetectionBoxes_Recall/AR@100 = 0.32984748, DetectionBoxes_Recall/AR@100 (large) = 0.3586111, DetectionBoxes_Recall/AR@100 (medium) = 0.21666667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.209749, Loss/localization_loss = 2.0638218, Loss/regularization_loss = 0.25180376, Loss/total_loss = 9.525373, global_step = 1237, learning_rate = 0.004, loss = 9.525373\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1237: training/model.ckpt-1237\n",
      "I0208 20:19:46.548210 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1237: training/model.ckpt-1237\n",
      "INFO:tensorflow:global_step/sec: 0.283469\n",
      "I0208 20:23:24.761129 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.283469\n",
      "INFO:tensorflow:loss = 4.2146015, step = 1301 (352.772 sec)\n",
      "I0208 20:23:24.762115 140033311766336 basic_session_run_hooks.py:260] loss = 4.2146015, step = 1301 (352.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302776\n",
      "I0208 20:28:55.038132 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.302776\n",
      "INFO:tensorflow:loss = 3.852558, step = 1401 (330.277 sec)\n",
      "I0208 20:28:55.038983 140033311766336 basic_session_run_hooks.py:260] loss = 3.852558, step = 1401 (330.277 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1412 into training/model.ckpt.\n",
      "I0208 20:29:31.297358 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 1412 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 20:29:33.426695 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:29:35.817305 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:29:35.860851 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:29:35.897593 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:29:35.941087 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:29:35.982047 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:29:36.022082 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 20:29:37.884502 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T20:29:37Z\n",
      "I0208 20:29:37.901862 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T20:29:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 20:29:38.331365 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-1412\n",
      "I0208 20:29:38.332513 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-1412\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 20:29:40.478361 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 20:29:40.657954 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 20:29:46.985949 140030026708736 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 20:29:46.987112 140030026708736 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 20:29:46.990767 140030026708736 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-08-20:29:47\n",
      "I0208 20:29:47.591343 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-20:29:47\n",
      "INFO:tensorflow:Saving dict for global step 1412: DetectionBoxes_Precision/mAP = 0.1496345, DetectionBoxes_Precision/mAP (large) = 0.17094807, DetectionBoxes_Precision/mAP (medium) = 0.0036533677, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.34067315, DetectionBoxes_Precision/mAP@.75IOU = 0.052383393, DetectionBoxes_Recall/AR@1 = 0.13572985, DetectionBoxes_Recall/AR@10 = 0.23028323, DetectionBoxes_Recall/AR@100 = 0.29607844, DetectionBoxes_Recall/AR@100 (large) = 0.29527777, DetectionBoxes_Recall/AR@100 (medium) = 0.25, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 8.528157, Loss/localization_loss = 2.1922753, Loss/regularization_loss = 0.2524319, Loss/total_loss = 10.972863, global_step = 1412, learning_rate = 0.004, loss = 10.972863\n",
      "I0208 20:29:47.591596 140033311766336 estimator.py:2049] Saving dict for global step 1412: DetectionBoxes_Precision/mAP = 0.1496345, DetectionBoxes_Precision/mAP (large) = 0.17094807, DetectionBoxes_Precision/mAP (medium) = 0.0036533677, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.34067315, DetectionBoxes_Precision/mAP@.75IOU = 0.052383393, DetectionBoxes_Recall/AR@1 = 0.13572985, DetectionBoxes_Recall/AR@10 = 0.23028323, DetectionBoxes_Recall/AR@100 = 0.29607844, DetectionBoxes_Recall/AR@100 (large) = 0.29527777, DetectionBoxes_Recall/AR@100 (medium) = 0.25, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 8.528157, Loss/localization_loss = 2.1922753, Loss/regularization_loss = 0.2524319, Loss/total_loss = 10.972863, global_step = 1412, learning_rate = 0.004, loss = 10.972863\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1412: training/model.ckpt-1412\n",
      "I0208 20:29:47.594888 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1412: training/model.ckpt-1412\n",
      "INFO:tensorflow:global_step/sec: 0.289074\n",
      "I0208 20:34:40.969738 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.289074\n",
      "INFO:tensorflow:loss = 3.4469893, step = 1501 (345.932 sec)\n",
      "I0208 20:34:40.970553 140033311766336 basic_session_run_hooks.py:260] loss = 3.4469893, step = 1501 (345.932 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1590 into training/model.ckpt.\n",
      "I0208 20:39:34.269172 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 1590 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 20:39:36.459358 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:39:38.842387 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:39:38.876035 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:39:38.915030 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:39:38.951933 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:39:38.989171 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:39:39.026039 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 20:39:40.552174 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T20:39:40Z\n",
      "I0208 20:39:40.570085 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T20:39:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 20:39:40.998553 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-1590\n",
      "I0208 20:39:40.999899 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-1590\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 20:39:42.736750 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 20:39:42.895841 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 20:39:48.839843 140030026708736 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 20:39:48.840515 140030026708736 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 20:39:48.844267 140030026708736 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.479\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.409\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.438\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-20:39:49\n",
      "I0208 20:39:49.401238 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-20:39:49\n",
      "INFO:tensorflow:Saving dict for global step 1590: DetectionBoxes_Precision/mAP = 0.21694195, DetectionBoxes_Precision/mAP (large) = 0.22618668, DetectionBoxes_Precision/mAP (medium) = 0.20657288, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.47946692, DetectionBoxes_Precision/mAP@.75IOU = 0.1493628, DetectionBoxes_Recall/AR@1 = 0.2093682, DetectionBoxes_Recall/AR@10 = 0.40915033, DetectionBoxes_Recall/AR@100 = 0.41699347, DetectionBoxes_Recall/AR@100 (large) = 0.4377778, DetectionBoxes_Recall/AR@100 (medium) = 0.28333333, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.615205, Loss/localization_loss = 1.7047223, Loss/regularization_loss = 0.2530532, Loss/total_loss = 9.572982, global_step = 1590, learning_rate = 0.004, loss = 9.572982\n",
      "I0208 20:39:49.401460 140033311766336 estimator.py:2049] Saving dict for global step 1590: DetectionBoxes_Precision/mAP = 0.21694195, DetectionBoxes_Precision/mAP (large) = 0.22618668, DetectionBoxes_Precision/mAP (medium) = 0.20657288, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.47946692, DetectionBoxes_Precision/mAP@.75IOU = 0.1493628, DetectionBoxes_Recall/AR@1 = 0.2093682, DetectionBoxes_Recall/AR@10 = 0.40915033, DetectionBoxes_Recall/AR@100 = 0.41699347, DetectionBoxes_Recall/AR@100 (large) = 0.4377778, DetectionBoxes_Recall/AR@100 (medium) = 0.28333333, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.615205, Loss/localization_loss = 1.7047223, Loss/regularization_loss = 0.2530532, Loss/total_loss = 9.572982, global_step = 1590, learning_rate = 0.004, loss = 9.572982\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1590: training/model.ckpt-1590\n",
      "I0208 20:39:49.403660 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1590: training/model.ckpt-1590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.289976\n",
      "I0208 20:40:25.825999 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.289976\n",
      "INFO:tensorflow:loss = 3.8923295, step = 1601 (344.856 sec)\n",
      "I0208 20:40:25.826720 140033311766336 basic_session_run_hooks.py:260] loss = 3.8923295, step = 1601 (344.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302442\n",
      "I0208 20:45:56.467525 140033311766336 basic_session_run_hooks.py:692] global_step/sec: 0.302442\n",
      "INFO:tensorflow:loss = 3.8252072, step = 1701 (330.642 sec)\n",
      "I0208 20:45:56.468236 140033311766336 basic_session_run_hooks.py:260] loss = 3.8252072, step = 1701 (330.642 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1766 into training/model.ckpt.\n",
      "I0208 20:49:36.023094 140033311766336 basic_session_run_hooks.py:606] Saving checkpoints for 1766 into training/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0208 20:49:38.213791 140033311766336 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:49:41.120332 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:49:41.155087 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:49:41.193692 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:49:41.231037 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:49:41.266985 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0208 20:49:41.302834 140033311766336 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0208 20:49:42.909001 140033311766336 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-08T20:49:42Z\n",
      "I0208 20:49:42.927884 140033311766336 evaluation.py:255] Starting evaluation at 2020-02-08T20:49:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0208 20:49:43.364840 140033311766336 monitored_session.py:240] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-1766\n",
      "I0208 20:49:43.366034 140033311766336 saver.py:1284] Restoring parameters from training/model.ckpt-1766\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0208 20:49:45.629113 140033311766336 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0208 20:49:45.807287 140033311766336 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 27 images.\n",
      "I0208 20:49:52.397988 140030026708736 coco_evaluation.py:205] Performing evaluation on 27 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0208 20:49:52.398694 140030026708736 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0208 20:49:52.402477 140030026708736 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-08-20:49:52\n",
      "I0208 20:49:52.954022 140033311766336 evaluation.py:275] Finished evaluation at 2020-02-08-20:49:52\n",
      "INFO:tensorflow:Saving dict for global step 1766: DetectionBoxes_Precision/mAP = 0.30164006, DetectionBoxes_Precision/mAP (large) = 0.33453867, DetectionBoxes_Precision/mAP (medium) = 0.17616843, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.7297271, DetectionBoxes_Precision/mAP@.75IOU = 0.15253012, DetectionBoxes_Recall/AR@1 = 0.23921569, DetectionBoxes_Recall/AR@10 = 0.39912853, DetectionBoxes_Recall/AR@100 = 0.40893245, DetectionBoxes_Recall/AR@100 (large) = 0.41222224, DetectionBoxes_Recall/AR@100 (medium) = 0.34444445, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.5882883, Loss/localization_loss = 1.5920923, Loss/regularization_loss = 0.2536659, Loss/total_loss = 9.434047, global_step = 1766, learning_rate = 0.004, loss = 9.434047\n",
      "I0208 20:49:52.954270 140033311766336 estimator.py:2049] Saving dict for global step 1766: DetectionBoxes_Precision/mAP = 0.30164006, DetectionBoxes_Precision/mAP (large) = 0.33453867, DetectionBoxes_Precision/mAP (medium) = 0.17616843, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.7297271, DetectionBoxes_Precision/mAP@.75IOU = 0.15253012, DetectionBoxes_Recall/AR@1 = 0.23921569, DetectionBoxes_Recall/AR@10 = 0.39912853, DetectionBoxes_Recall/AR@100 = 0.40893245, DetectionBoxes_Recall/AR@100 (large) = 0.41222224, DetectionBoxes_Recall/AR@100 (medium) = 0.34444445, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 7.5882883, Loss/localization_loss = 1.5920923, Loss/regularization_loss = 0.2536659, Loss/total_loss = 9.434047, global_step = 1766, learning_rate = 0.004, loss = 9.434047\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1766: training/model.ckpt-1766\n",
      "I0208 20:49:52.958088 140033311766336 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1766: training/model.ckpt-1766\n"
     ]
    }
   ],
   "source": [
    "!python /home/ghost/Desktop/experiment/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "KP-tUdtnRybs",
    "outputId": "effcee05-b801-442e-f4ed-1f7f13a0cf33"
   },
   "outputs": [],
   "source": [
    "!ls {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1Nrqw3nqnCh"
   },
   "outputs": [],
   "source": [
    "# Legacy way of training(also works).\n",
    "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmSESMetj1sa"
   },
   "source": [
    "## Exporting a Trained Inference Graph\n",
    "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16746
    },
    "colab_type": "code",
    "id": "DHoP90pUyKSq",
    "outputId": "3d03f9db-2ec6-4255-ee19-f2fdbd9eb66d"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "!python /home/ghost/Desktop/experiment/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "usgBZvkz0nqD",
    "outputId": "e81cb36a-316a-4ed2-f6d6-8b3501c4e204"
   },
   "outputs": [],
   "source": [
    "!ls {output_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p09AOThWkaQv"
   },
   "source": [
    "## Download the model `.pb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnDo1lonKgFr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
    "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lHqWkLBINYoI",
    "outputId": "07644b92-19df-46a3-db22-d97df933c688"
   },
   "outputs": [],
   "source": [
    "!ls -alh {pb_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIqnjbWYsuQw"
   },
   "source": [
    "### Option1 : upload the `.pb` file to your Google Drive\n",
    "Then download it from your Google Drive to local file system.\n",
    "\n",
    "During this step, you will be prompted to enter the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "hAqyASIJqjae",
    "outputId": "3fcf1a18-1e27-4361-b886-5b0c71c46217"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "fname = os.path.basename(pb_fname)\n",
    "# Create & upload a text file.\n",
    "uploaded = drive.CreateFile({'title': fname})\n",
    "uploaded.SetContentFile(pb_fname)\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FKFq8RXs6bs"
   },
   "source": [
    "### Option2 :  Download the `.pb` file directly to your local file system\n",
    "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "-bP0iMMnnr77",
    "outputId": "86ed702c-2715-46bd-8249-0e8c21ba7141"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(pb_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFyCeiBb9BbS"
   },
   "source": [
    "### Download the `label_map.pbtxt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1TbL6Ox8q6Z"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(label_map_pbtxt_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUmAo9foa1xq"
   },
   "source": [
    "### Download the modified pipline file\n",
    "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pql2QpemazE1"
   },
   "outputs": [],
   "source": [
    "files.download(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1AgBj1l0v_W"
   },
   "outputs": [],
   "source": [
    "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
    "# from google.colab import files\n",
    "# files.download('fine_tuned_model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mz1gX19GlVW7"
   },
   "source": [
    "## Run inference test\n",
    "Test with images in repository `object_detection_demo/test` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Pzj9A4e5mj5l",
    "outputId": "5c8dcbc2-74db-4114-ed71-e66e8dfa038b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = pb_fname\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "\n",
    "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
    "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
    "\n",
    "assert os.path.isfile(pb_fname)\n",
    "assert os.path.isfile(PATH_TO_LABELS)\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
    "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
    "print(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1443
    },
    "colab_type": "code",
    "id": "CG5YUMdg1Po7",
    "outputId": "a9f78425-ce58-465f-e8c3-87c1df320d74"
   },
   "outputs": [],
   "source": [
    "%cd /home/ghost/Desktop/experiment/models/research/object_detection\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {\n",
    "                output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                        tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(\n",
    "                    tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(\n",
    "                    tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(\n",
    "                    tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
    "                                           real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
    "                                           real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(\n",
    "                output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image = Image.open(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GStNeHWPkTcN"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "tensorflow-object-detection-training-colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
